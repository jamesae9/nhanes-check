<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>NHANES Manuscript Checker (Python)</title> <!-- Reverted Title -->
  
  <!-- Document processing libraries -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mammoth/1.4.19/mammoth.browser.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.16.105/pdf.min.js"></script>
  
  <!-- Pyodide - Python in the browser -->
  <script src="https://cdn.jsdelivr.net/pyodide/v0.23.4/full/pyodide.js"></script>
  
  <!-- Embedded CSS (no external file needed) -->
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 20px;
      line-height: 1.6;
      color: #333;
    }
    .container {
      max-width: 1000px;
      margin: 0 auto;
    }
    h1 {
      color: #2c3e50;
      margin-bottom: 30px;
    }
    h2 {
      color: #3498db;
      margin-top: 30px;
      border-bottom: 1px solid #eee;
      padding-bottom: 10px;
    }
    .upload-section {
      background-color: #f9f9f9;
      padding: 20px;
      border-radius: 5px;
      border: 1px solid #ddd;
      margin-bottom: 20px;
    }
    textarea {
      width: 100%;
      padding: 10px;
      border: 1px solid #ddd;
      border-radius: 4px;
      font-size: 14px;
      font-family: inherit;
      box-sizing: border-box;
    }
    .button-container {
      margin: 20px 0;
    }
    button {
      background-color: #3498db;
      color: white;
      border: none;
      padding: 10px 20px;
      border-radius: 4px;
      cursor: pointer;
      font-size: 16px;
      transition: background-color 0.3s;
    }
    button:hover {
      background-color: #2980b9;
    }
    button:disabled {
      background-color: #95a5a6;
      cursor: not-allowed;
    }
    .results-section {
      background-color: white;
      padding: 20px;
      border-radius: 5px;
      border: 1px solid #ddd;
      margin-top: 20px;
    }
    .check-item {
      margin-bottom: 15px;
      padding: 15px;
      border-radius: 4px;
    }
    .pass {
      background-color: #e7f7e7;
      border-left: 4px solid #28a745;
    }
    .fail {
      background-color: #ffeaea;
      border-left: 4px solid #dc3545;
    }
    .not-nhanes {
      background-color: #f8f9fa;
      border-left: 4px solid #6c757d;
    }
    .skipped {
      background-color: #f8f9fa;
      border-left: 4px solid #6c757d;
    }
    .hidden {
      display: none;
    }
    .file-upload {
      margin: 15px 0;
    }
    .summary {
      font-weight: bold;
      font-size: 18px;
      margin-bottom: 20px;
    }
    .pyodide-loading {
      text-align: center;
      padding: 20px;
      font-weight: bold;
      color: #3498db;
    }
    .loading-indicator {
      margin-top: 10px;
      font-style: italic;
      color: #666;
    }
    .footer {
      margin-top: 30px;
      text-align: center;
      font-size: 14px;
      color: #777;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>NHANES Manuscript Checker (Python)</h1> <!-- Reverted Title -->
    
    <div id="pyodideLoading" class="pyodide-loading">
      <div>Loading Python environment... Please wait.</div>
      <div class="loading-indicator">This may take a moment on first load.</div>
      <div id="loadingProgress">Initializing...</div>
    </div>
    
    <div id="appContent" class="hidden">
      <div class="upload-section">
        <h2>Check Manuscript</h2>
        <p>Paste manuscript text or upload a file below:</p>
        <textarea id="manuscriptText" rows="10" placeholder="Paste manuscript text here..."></textarea>
        <div class="file-upload">
          <label for="manuscriptFile">Or upload a file:</label>
          <input type="file" id="manuscriptFile" accept=".txt,.docx,.pdf">
        </div>
        <div class="button-container">
          <button id="checkButton" disabled>Check Manuscript</button>
          <button id="clearButton">Clear</button>
        </div>
      </div>
      <div class="results-section hidden" id="results">
        <h2>NHANES Manuscript Check Results</h2> <!-- Reverted Header -->
        <div id="resultsContent"></div>
      </div>
    </div>
    
    <footer class="footer">
      <p>NHANES Manuscript Checker (Python/Pyodide Version)</p>
    </footer>
  </div>

  <script>
    window.NHANESBridge = { // Keep name or rename if preferred
      async fetchTextFromFile(file) {
        return new Promise((resolve, reject) => {
          const reader = new FileReader();
          reader.onload = (e) => resolve(e.target.result);
          reader.onerror = (e) => reject(new Error(`Error reading file (text): ${e.target.error}`));
          reader.readAsText(file);
        });
      },
      async fetchArrayBufferFromFile(file) {
        return new Promise((resolve, reject) => {
          const reader = new FileReader();
          reader.onload = (e) => resolve(e.target.result); 
          reader.onerror = (e) => reject(new Error(`Error reading file (arraybuffer): ${e.target.error}`));
          reader.readAsArrayBuffer(file);
        });
      },
      showUILoading(message = "Processing...") {
        const ta = document.getElementById('manuscriptText');
        const cb = document.getElementById('checkButton');
        const clb = document.getElementById('clearButton');
        const fi = document.getElementById('manuscriptFile');
        if (ta) { ta.value = message; ta.disabled = true; }
        if (cb) cb.disabled = true;
        if (clb) clb.disabled = true;
        if (fi) fi.disabled = true;
      },
      hideUILoading(enableCheckButton = true) {
        const ta = document.getElementById('manuscriptText');
        const cb = document.getElementById('checkButton');
        const clb = document.getElementById('clearButton');
        const fi = document.getElementById('manuscriptFile');
        if (ta) ta.disabled = false;
        if (clb) clb.disabled = false;
        if (fi) fi.disabled = false;
        if (ta && cb) {
            const text = ta.value.trim(); 
            const isMsg = text.startsWith("Loading") || text.startsWith("Error") || text.startsWith("Unsupported");
            cb.disabled = !text || isMsg || !enableCheckButton;
        }
      }
    };
    function updateLoadingStatus(message) {
      const pe = document.getElementById('loadingProgress');
      if (pe) pe.textContent = message;
    }
    window.updateLoadingStatus = updateLoadingStatus;

    async function main() {
      try {
        updateLoadingStatus("Loading Pyodide core...");
        const pyodide = await loadPyodide();
        window.pyodide = pyodide;
        updateLoadingStatus("Loading Python packages...");
        updateLoadingStatus("Loading NHANES Checker implementation...");
        
        const pythonCode = `
import re
import js 
from pyodide.ffi import create_proxy, to_js, JsException
from js import document, console, alert, window 
import traceback 
from datetime import datetime

# --- NHANES Checker Functions ---
def check_for_nhanes(text):
    # Simple check if the text mentions NHANES
    nhanes_regex = r'\\bNHANES\\b|\\bNational Health and Nutrition Examination Survey\\b'
    return bool(re.search(nhanes_regex, text, re.IGNORECASE))

# --- Removed Functions ---
# check_nhanes_citation
# check_survey_design_acknowledgment
# check_weighting_methodology
# check_nhanes_date_range (logic merged into new function)
# check_nhanes_cycle_recency (logic merged into new function)

# --- NEW Combined Date Check Function ---
def check_nhanes_date_context_and_validation(text):
    """
    Finds YYYY-YYYY ranges near NHANES mentions, validates them for 
    plausibility (start>=1959), odd-even pattern, and recency (end within last 15 years).
    """
    MIN_START_YEAR = 1959 
    current_year = datetime.now().year
    MAX_END_YEAR = current_year
    RECENCY_YEAR_THRESHOLD = current_year - 15

    # Regex patterns need double backslashes for JS template literal
    pattern1 = r'\\b(?:NHANES|National\\sHealth\\sand\\sNutrition\\sExamination\\sSurvey)\\b[^\\d\\n\\(]*?\\(?(\\d{4})\\)?\\s*[-–—]\\s*\\(?(\\d{4})\\)?'
    pattern2 = r'\\(?(\\d{4})\\)?\\s*[-–—]\\s*\\(?(\\d{4})\\)?[^\\d\\n]*?\\b(?:NHANES|National\\sHealth\\sand\\sNutrition\\sExamination\\sSurvey)\\b'
    combined_regex = f"({pattern1})|({pattern2})"

    found_ranges = {} 

    for match in re.finditer(combined_regex, text, re.IGNORECASE):
        start_year_str, end_year_str = None, None
        if match.group(2) and match.group(3): 
            start_year_str, end_year_str = match.group(2), match.group(3)
        elif match.group(5) and match.group(6):
            start_year_str, end_year_str = match.group(5), match.group(6)

        if start_year_str and end_year_str:
            try:
                start_year = int(start_year_str)
                end_year = int(end_year_str)
                range_key = f"{start_year}-{end_year}"

                if range_key in found_ranges: continue

                is_plausible = (start_year >= MIN_START_YEAR and 
                                end_year <= MAX_END_YEAR and 
                                start_year <= end_year)
                is_odd_even = (start_year % 2 == 1 and end_year % 2 == 0) if is_plausible else False
                is_recent = (end_year >= RECENCY_YEAR_THRESHOLD) if is_plausible else False
                is_valid = is_plausible and is_odd_even and is_recent

                found_ranges[range_key] = {
                    "plausible": is_plausible, "odd_even": is_odd_even,
                    "recent": is_recent, "valid": is_valid
                }
            except ValueError:
                js.console.warn(f"[Python] Could not parse years from match: {start_year_str}-{end_year_str}")
                continue

    if not found_ranges:
        return {'passed': True, 'details': "No date ranges found near NHANES mentions."}

    details_list = ["Date ranges found near NHANES mentions:"]
    overall_valid_found = False
    for range_key, status in found_ranges.items():
        detail = f"- {range_key}: "
        valid_parts = []
        invalid_parts = []
        if status["plausible"]: valid_parts.append("Plausible")
        else: invalid_parts.append("Not Plausible")
        if status["odd_even"]: valid_parts.append("Odd-Even OK")
        else: invalid_parts.append("Fails Odd-Even")
        if status["recent"]: valid_parts.append("Recent")
        else: invalid_parts.append("Not Recent")
            
        if status["valid"]:
            detail += "VALID (✓ Plausible, ✓ Odd-Even, ✓ Recent)"
            overall_valid_found = True
        else:
            detail += f"INVALID (Plausible: {'Yes' if status['plausible'] else 'No'}, "
            detail += f"Odd-Even: {'Yes' if status['odd_even'] else 'No'}, "
            detail += f"Recent: {'Yes' if status['recent'] else 'No'})"
        details_list.append(detail)

    summary = "Overall Summary: " + ("At least one valid date range found associated with NHANES." if overall_valid_found else "No date ranges associated with NHANES met all validation criteria (Plausible, Odd-Even, Recent).")
    details_list.append(summary)
    
    passed = overall_valid_found 
    return {'passed': passed, 'details': "\\n".join(details_list)}

# --- Remaining Check Functions (Topics, Title, Author Flags) ---

def extract_manuscript_topics(text): 
    title_match = re.search(r'^(?:Title\\s*[:\\s]*)?([^\\n]+)', text, re.IGNORECASE)
    abstract_regex_pattern = r'\\bAbstract\\b([\\s\\S]*?)(?=\\n\\s*\\b(?:Keywords|Introduction|Background|Methods)\\b|\\n{2,})' 
    
    title = title_match.group(1).strip() if title_match and title_match.group(1) else ""
    
    actual_abstract_match_object = re.search(abstract_regex_pattern, text, re.IGNORECASE)
    abstract = actual_abstract_match_object.group(1).strip() if actual_abstract_match_object and actual_abstract_match_object.group(1) else ""
    
    analysis_text = (title + " " + abstract).strip() 
    if not analysis_text:
        analysis_text = text[:min(len(text), 3000)] 

    if not analysis_text: return ["General Health/Unknown"]
    
    health_domains = {
        "Cardiovascular": ["heart", "cardiac", "cardiovascular", "blood pressure", "hypertension", "cholesterol", "stroke", "atherosclerosis", "vascular", "lipids", "arrhythmia"],
        "Nutrition/Diet": ["diet", "dietary", "food", "nutrition", "nutrient", "intake", "consumption", "supplement", "eating pattern", "malnutrition", "vitamin", "mineral", "fiber", "calories"],
        "Metabolic/Endocrine": ["diabetes", "insulin", "glucose", "metabolic syndrome", "obesity", "BMI", "body mass index", "thyroid", "endocrine", "adiposity", "waist circumference", "hormone"],
        "Epidemiology/Public Health": ["prevalence", "incidence", "risk factor", "population", "demographic", "public health", "mortality", "morbidity", "surveillance", "trends", "disparities", "socioeconomic", "nationally representative", "cohort", "prognostic", "prognostic indicator", "nhanes" ],
        "Mental Health/Neurology": ["depression", "anxiety", "psychiatric", "mental", "psychological", "cognitive", "cognition", "neurologic", "stress", "mood", "suicide"],
        "Respiratory": ["lung", "pulmonary", "respiratory", "asthma", "COPD", "breathing", "sleep apnea", "spirometry", "chronic lower respiratory disease", "influenza", "pneumonia"],
        "Oncology": ["cancer", "tumor", "oncology", "malignancy", "carcinoma", "neoplasm"],
        "Pediatrics": ["child", "children", "adolescent", "pediatric", "youth", "infant", "growth", "development"],
        "Geriatrics": ["elderly", "older adults", "aging", "geriatric", "seniors", "frailty"],
        "Renal/Urology": ["kidney", "renal", "nephrology", "chronic kidney disease", "CKD", "urinary", "urology"],
        "Musculoskeletal/Physical Activity": ["bone", "muscle", "physical activity", "exercise", "sedentary", "osteoporosis", "arthritis", "sarcopenia", "fitness", "orthopedic", "musculoskeletal", "spine"],
        "Environmental Health": ["exposure", "pollutant", "environment", "toxin", "heavy metal", "pesticide", "air quality", "lead", "mercury", "cadmium"],
        "Infectious Disease": ["infection", "virus", "bacteria", "antibody", "vaccine", "hepatitis", "HIV", "influenza", "pneumonia"],
        "Gastroenterology": ["gut", "gastrointestinal", "liver", "hepatic", "digestive"],
        "Allergy/Immunology": [ "allergy", "asthma", "immune", "inflammation", "antibody", "inflammatory marker", "neutrophil", "platelet", "monocyte", "lymphocyte", "pan-immune"]
    }
    domain_scores = {domain: 0 for domain in health_domains}
    for domain, keywords in health_domains.items():
        for keyword in keywords:
            regex = r'\\b' + re.escape(keyword) + r'\\b' 
            domain_scores[domain] += len(re.findall(regex, analysis_text, re.IGNORECASE) or [])
    
    sorted_domains = sorted([(d, s) for d, s in domain_scores.items() if s > 0], key=lambda x: x[1], reverse=True)
    
    min_score_threshold = 1 
    top_n = 4 

    candidate_domains = [
        domain for domain, score in sorted_domains 
        if score >= min_score_threshold
    ]
    final_top_domains = candidate_domains[:top_n]
    
    return final_top_domains if final_top_domains else ["General Health/Mixed"]

def check_title_template(text): 
    title_regex_pattern = r'^(?:Title\\s*[:\\s]*)?([^\\n]+)'
    title_match = re.search(title_regex_pattern, text, re.IGNORECASE)
    
    if not title_match or not title_match.group(1):
        return {
            'passed': True, 
            'details': "Could not reliably extract a title to check for templating."
        }
    
    title = title_match.group(1).strip()
    title_lower = title.lower()

    association_keywords = ['association', 'relationship', 'correlation', 'link', 'impact', 'effect', 'influence', 'predictor', 'association with']
    association_prepositions = ['between', 'among', 'of', 'on', 'with']
    found_association_keyword = any(re.search(r'\\b' + re.escape(kw) + r'\\b', title_lower) for kw in association_keywords)
    found_association_preposition = any(re.search(r'\\b' + re.escape(prep) + r'\\b', title_lower) for prep in association_prepositions)
    has_association_structure = found_association_keyword and found_association_preposition

    population_indicators = ['U.S. adults', 'US adults', 'American adults', 'U.S. population', 'US population','adults', 'children', 'adolescents', 'participants', 'individuals', 'subjects', 'men', 'women', 'patients', 'older adults', 'elderly']
    has_population_statement = any(re.search(r'\\b' + re.escape(pop_term) + r'\\b', title_lower) for pop_term in population_indicators)

    study_design_keywords = ['cross-sectional', 'cross sectional', 'longitudinal', 'cohort', 'survey', 'analysis', 'study', 'examination'] 
    has_study_design = any(re.search(r'\\b' + re.escape(design) + r'\\b', title_lower) for design in study_design_keywords)

    nhanes_with_colon_pattern = r':.*?\\b(NHANES|National Health and Nutrition Examination Survey)\\b|\\b(NHANES|National Health and Nutrition Examination Survey)\\b:'
    specifies_nhanes_with_colon = bool(re.search(nhanes_with_colon_pattern, title, re.IGNORECASE)) 
    
    issues_found = []; details_list = []
    if has_association_structure: issues_found.append("association structure"); details_list.append("✓ Title appears to outline an association/relationship.")
    else: details_list.append("✗ Title may not clearly outline an association/relationship.")
    if has_population_statement: issues_found.append("population statement"); details_list.append("✓ Title appears to state a population of interest.")
    else: details_list.append("✗ Title may not clearly state a population of interest.")
    if has_study_design: issues_found.append("study design mentioned"); details_list.append("✓ Title appears to mention a study design or type.")
    else: details_list.append("✗ Title may not mention a study design or type.")
    if specifies_nhanes_with_colon: issues_found.append("NHANES with colon"); details_list.append("✓ Title specifies NHANES as data source with colon formatting.")
    else: details_list.append("○ Title does not use the specific ': NHANES' or 'NHANES:' formatting.")

    number_of_template_indicators = len(issues_found)
    passed = True; summary_detail = f"Title: \\"{title}\\". "
    if number_of_template_indicators >= 3: passed = False; summary_detail += f"Appears templated based on {number_of_template_indicators} common elements ({', '.join(issues_found)})."
    elif number_of_template_indicators == 2 and specifies_nhanes_with_colon: passed = False; summary_detail += f"Appears somewhat templated due to 'NHANES with colon' and one other element ({', '.join(issues_found)})."
    elif number_of_template_indicators >= 2: summary_detail += f"Shows some signs of templating with {number_of_template_indicators} elements ({', '.join(issues_found)})."
    else: summary_detail += "Does not show strong signs of common templating patterns.";
    if number_of_template_indicators > 0 and passed: summary_detail += f" (Found {', '.join(issues_found)})."
    full_details = summary_detail + "\\n" + "\\n".join(details_list)
    return {'passed': passed, 'details': full_details}

def check_author_red_flags(full_manuscript_text, text_for_checks):
    topics = extract_manuscript_topics(text_for_checks) 
    js.console.log(f"[Python DEBUG] Paper topics for affil relevance: {topics}")
    
    author_section_regex = r'(?:\\bAbstract\\b[\\s\\S]*?)(?:\\n\\s*(?:Authors?|Affiliations?)\\b\\s*[:\\n]?)([\\s\\S]*?)(?=\\n\\s*\\b(?:Introduction|Background|Methods|Results|Discussion|Conclusion|References|Acknowledgments|Funding|Conflict\s+of\s+Interest|Ethical\s+Approval|Data\s+Availability|Competing\s+Interests)\\b|\\n{3,})'
    author_section_match = re.search(author_section_regex, text_for_checks, re.IGNORECASE) 
    author_section_text_block = ""

    if author_section_match and author_section_match.group(1):
        author_section_text_block = author_section_match.group(1).strip()
        js.console.log(f"[Python DEBUG] Author section extracted from main body, length: {len(author_section_text_block)}")
    
    if not author_section_text_block: 
        first_part_of_full_text = full_manuscript_text[:4000] 
        author_section_match_fallback = re.search(author_section_regex, first_part_of_full_text, re.IGNORECASE)
        if author_section_match_fallback and author_section_match_fallback.group(1):
            author_section_text_block = author_section_match_fallback.group(1).strip()
            js.console.log(f"[Python DEBUG] Author section extracted from fallback (start of full text), length: {len(author_section_text_block)}")
        else: 
            email_regex_global = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b'
            affiliation_keyword_global = r'\\b(?:Department|Division|School|Faculty|Center|Institute|Hospital|University|College|Laboratory|Program|Unit|Clinic|Affiliation|Correspondence)\\b'
            potential_author_area = full_manuscript_text[:2000] 
            if (re.search(email_regex_global, potential_author_area, re.IGNORECASE) or 
                re.search(affiliation_keyword_global, potential_author_area, re.IGNORECASE)):
                author_section_text_block = potential_author_area 
                js.console.log(f"[Python DEBUG] Author section inferred from broad search at start of text, length: {len(author_section_text_block)}")
            else:
                js.console.log("[Python DEBUG] Could not identify a distinct author information block.")
                return {
                    'passed': True, 
                    'details': "Author information block not clearly identified; detailed author checks skipped."
                }

    if not author_section_text_block.strip():
        js.console.log("[Python DEBUG] Author section block is empty after all fallbacks.")
        return {
            'passed': True,
            'details': "No author information content found to perform detailed checks."
        }

    email_regex = r'\\b[A-Za-z0-9._%+-]+@([A-Za-z0-9.-]+\\.[A-Za-z]{2,})\\b'
    non_institutional_domains = ['gmail\\\\.com', 'yahoo\\\\.com', 'hotmail\\\\.com', 'outlook\\\\.com', 
                                 'aol\\\\.com', 'icloud\\\\.com', 'protonmail\\\\.com', 'qq\\\\.com', 
                                 '163\\\\.com', 'mail\\\\.com', 'yandex\\\\.com']
    non_inst_pattern = r'(?:' + '|'.join(non_institutional_domains) + r')$' 
    
    all_email_domains_list = re.findall(email_regex, author_section_text_block)
    num_all_emails = len(all_email_domains_list)
    non_institutional_email_matches = [domain for domain in all_email_domains_list if re.search(non_inst_pattern, domain, re.IGNORECASE)]
    num_non_inst_emails = len(non_institutional_email_matches)

    email_report_details = f"Email analysis: {num_non_inst_emails}/{num_all_emails} non-institutional emails found."
    flag_non_institutional_emails = (num_all_emails > 0 and num_non_inst_emails >=1 and (num_all_emails > 0 and num_non_inst_emails / num_all_emails > 0.5))
    if num_all_emails == 0:
        email_report_details = "Email analysis: No author emails found in the extracted author section."

    # --- START OF REFINED AFFILIATION PARSING ---
    extracted_departmental_units = []
    affiliation_lines = [line.strip() for line in author_section_text_block.split('\\n') if line.strip()] 
    js.console.log(f"[Python DEBUG] Number of lines in author_section_text_block after split: {len(affiliation_lines)}")

    affiliation_line_keywords = [
        "university", "hospital", "institute", "school", "department", 
        "college", "center", "centre", "laboratory", "clinic", 
        "foundation", "research", "faculty", "program", "division", "section",
        "polytechnic", "academy" 
    ]
    non_affiliation_line_starters = [
        "these authors contributed", "corresponding author", "email:", "emails:",
        "author contributions", "acknowledgments", "funding", "conflict of interest",
        "competing interests", "ethical approval", "data availability", "consent for publication",
        "contributions:", "disclosure", "supported by", "received ", "accepted ", "published ",
        "keywords:", "abstract"
    ]
    affiliation_marker_regex = r'^\\s*(?:[\\(\\[]?\\s*[a-zA-Z0-9]+[\\s\\)\\]]*[.:])\\s*'

    for line_idx, line in enumerate(affiliation_lines):
        line_lower = line.lower()
        original_line_for_debug = line

        if any(line_lower.startswith(starter) for starter in non_affiliation_line_starters):
            continue
        
        if '@' in line:
            if not any(aff_kw in line_lower for aff_kw in ["university", "hospital", "institute", "school", "department", "center"]):
                #js.console.log(f"[Python DEBUG] AffilParse Line {line_idx}: Skipped (likely email line): '{original_line_for_debug}'")
                continue
        
        if line.count(',') > 2 and sum(c.isdigit() for c in line) < 2 and \
           not any(aff_kw in line_lower for aff_kw in affiliation_line_keywords):
            parts = [p.strip() for p in line.split(',')]
            if len(parts) > 2 and all(len(p.split()) < 5 for p in parts):
                continue
        
        is_marked_affiliation = bool(re.match(affiliation_marker_regex, line))
        contains_affiliation_keyword_in_line = any(aff_kw in line_lower for aff_kw in affiliation_line_keywords)

        if not is_marked_affiliation and not contains_affiliation_keyword_in_line:
            continue

        department_candidate = ""
        line_content_no_marker = re.sub(affiliation_marker_regex, '', line).strip()

        if not line_content_no_marker:
            continue

        if ',' in line_content_no_marker:
            department_candidate = line_content_no_marker.split(',')[0].strip()
        else:
            department_candidate = line_content_no_marker 
        
        if department_candidate and len(department_candidate) > 3 and len(department_candidate) < 120 : 
            cleaned_unit = department_candidate.lower()
            
            generic_prefixes = sorted([ 
                "department of", "dept. of", "dept of", "division of", "school of", 
                "faculty of", "center for", "centre for", "institute of", "unit of", 
                "program in", "section of", "clinic of", "service of", "laboratory of",
                "department", "division", "school", "faculty", "center", "centre", 
                "institute", "unit", "program", "section", "clinic", "service", "laboratory"
            ], key=len, reverse=True)

            temp_cleaned_unit = cleaned_unit 
            for gp in generic_prefixes:
                if temp_cleaned_unit == gp: 
                    temp_cleaned_unit = "" 
                    break
                if temp_cleaned_unit.startswith(gp + " ") or temp_cleaned_unit.startswith(gp + ","):
                    stripped = temp_cleaned_unit[len(gp):].lstrip(' ,')
                    if stripped: 
                        temp_cleaned_unit = stripped
            cleaned_unit = temp_cleaned_unit.strip()

            common_place_names = ["china", "usa", "u.s.a", "united states", "uk", "united kingdom", 
                                  "japan", "germany", "france", "canada", "australia", "korea", "taiwan",
                                  "shanghai", "beijing", "london", "new york", "tokyo", "seoul", "berlin", "paris"]
            
            # Python: r'[\[\]()\d\s,.-]+' -> JS: r'[\\(\\[\\]\\d\\s,.-]+'
            is_just_number_or_short_code = bool(re.fullmatch(r'[\\(\\[\\]\\d\\s,.-]+', cleaned_unit)) and len(cleaned_unit) < 5

            if cleaned_unit and len(cleaned_unit) > 3 and not cleaned_unit in common_place_names and not is_just_number_or_short_code:
                extracted_departmental_units.append(cleaned_unit)
                js.console.log(f"[Python DEBUG] Extracted unit: '{cleaned_unit}' from line: '{original_line_for_debug}' (Derived from: '{department_candidate}')")
    # --- END OF REFINED AFFILIATION PARSING ---

    unique_affiliations = list(set(unit for unit in extracted_departmental_units if unit))
    num_unique_affiliations = len(unique_affiliations)
    js.console.log(f"[Python DEBUG] Final unique affiliation units for relevance check: {unique_affiliations}")
    
    affiliation_count_details = f"Affiliation count: Found {num_unique_affiliations} distinct affiliation units."
    flag_too_many_affiliations = num_unique_affiliations > 3 

    GENERAL_NON_HEALTH_KEYWORDS = [
        "computer science", "electrical engineering", "mechanical engineering", 
        "aerospace engineering", "astronomy", "particle physics", "nuclear engineering",
        "pure mathematics", "theoretical physics",
        "geology", "oceanography", "architecture", "urban planning", "civil engineering",
        "fine arts", "music", "performing arts", "humanities", "literature", "history", "philosophy",
        "linguistics", "archaeology", 
        "law", "business administration", "finance", 
        "software engineering", "information technology services"
    ]
    
    relevance_mappings = {
        "Cardiovascular": ["cardiology", "cardiovascular", "vascular", "heart", "hypertension", "lipids"],
        "Nutrition/Diet": ["nutrition", "dietetics", "dietary", "food science"],
        "Metabolic/Endocrine": ["endocrinology", "metabolic", "diabetes", "obesity", "thyroid"],
        "Epidemiology/Public Health": ["epidemiology", "public health", "biostatistics", "statistics", "preventive medicine", "population health"],
        "Mental Health/Neurology": ["psychiatry", "psychology", "neurology", "neuroscience", "cognitive"],
        "Respiratory": ["pulmonary", "respiratory", "lung", "thoracic"],
        "Oncology": ["oncology", "cancer", "neoplasm"],
        "Pediatrics": ["pediatric", "child health"],
        "Geriatrics": ["geriatric", "aging"],
        "Renal/Urology": ["nephrology", "renal", "kidney", "urology"],
        "Musculoskeletal/Physical Activity": ["orthopedic", "musculoskeletal", "sports medicine", "spine", "bone", "osteoporosis", "rheumatology"],
        "Environmental Health": ["environmental health", "toxicology", "exposure science"],
        "Infectious Disease": ["infectious disease", "virology", "bacteriology", "immunology"],
        "Gastroenterology": ["gastroenterology", "hepatology", "digestive"],
        "Allergy/Immunology": ["allergy", "immunology", "immune", "inflammation"],
        "General Health/Mixed": ["biostatistics", "bioinformatics", "research methodology", "data science", "clinical trial", "health services research"]
    }
    
    relevant_affiliations_count = 0
    distinctly_non_health_affiliations_count = 0 
    affiliation_relevance_details = "Affiliation relevance: No unique affiliations to check."
    flag_mismatched_affiliations = False
    affiliation_match_debug = []

    if unique_affiliations:
        for affil_text_lower in unique_affiliations:
            is_specifically_relevant_to_paper_topic = False
            is_generally_relevant_research_field = False
            is_distinctly_non_health = False
            matched_keywords_log = []

            for neg_kw in GENERAL_NON_HEALTH_KEYWORDS:
                if re.search(r'\\b' + re.escape(neg_kw) + r'\\b', affil_text_lower):
                    is_distinctly_non_health = True
                    matched_keywords_log.append(f"NON-HEALTH keyword: '{neg_kw}'")
                    break 

            if is_distinctly_non_health:
                distinctly_non_health_affiliations_count += 1
                affiliation_match_debug.append(f"'{affil_text_lower}' flagged as DISTINCTLY NON-HEALTH due to: {', '.join(matched_keywords_log)}")
            else:
                for topic in topics: 
                    specific_topic_keywords = relevance_mappings.get(topic, [])
                    for term in specific_topic_keywords:
                        if re.search(r'\\b' + re.escape(term) + r'\\b', affil_text_lower):
                            is_specifically_relevant_to_paper_topic = True
                            matched_keywords_log.append(f"{term} (topic: {topic})")
                
                if not is_specifically_relevant_to_paper_topic:
                    general_research_keywords = relevance_mappings.get("General Health/Mixed", [])
                    for term in general_research_keywords:
                        if re.search(r'\\b' + re.escape(term) + r'\\b', affil_text_lower):
                            is_generally_relevant_research_field = True
                            matched_keywords_log.append(f"{term} (general research field)")
            
                if is_specifically_relevant_to_paper_topic:
                    relevant_affiliations_count += 1
                    affiliation_match_debug.append(f"'{affil_text_lower}' SPECIFICALLY matched paper topic: {', '.join(matched_keywords_log)}")
                elif is_generally_relevant_research_field:
                    relevant_affiliations_count += 1 
                    affiliation_match_debug.append(f"'{affil_text_lower}' matched GENERAL research field: {', '.join(matched_keywords_log)}")
                else:
                    affiliation_match_debug.append(f"'{affil_text_lower}' - no specific or general health research field match found for topics: {', '.join(topics)}.")

        if num_unique_affiliations > 0:
            relevance_ratio = relevant_affiliations_count / num_unique_affiliations
            detail_parts = [f"{relevant_affiliations_count}/{num_unique_affiliations} affiliations appear relevant to paper topics ({', '.join(topics)})."]
            if distinctly_non_health_affiliations_count > 0:
                flag_mismatched_affiliations = True
                detail_parts.append(f"{distinctly_non_health_affiliations_count} affiliation(s) seem distinctly non-health related.")
            if not flag_mismatched_affiliations:
                if relevance_ratio < 0.4 and num_unique_affiliations > 1: 
                    flag_mismatched_affiliations = True
                    detail_parts.append("Low proportion of topic-specific affiliations.")
                elif num_unique_affiliations > 2 and relevance_ratio < 0.6: 
                    flag_mismatched_affiliations = True
                    detail_parts.append("Low proportion of topic-specific affiliations for multiple institutions.")
            affiliation_relevance_details = " ".join(detail_parts)
        else:
             affiliation_relevance_details = "Affiliation relevance: No unique affiliations found to check."

        js.console.log("[Python DEBUG] Affiliation Relevance Matches/Flags:")
        for dbg_msg in affiliation_match_debug:
            js.console.log(f"[Python DEBUG] - {dbg_msg}")
    
    author_contrib_regex = r'(?im)^\\s*(?:Author(?:s)?\\sContributions?)\s*:?\s*\\n([\\s\\S]*?)(?=\\n\\s*\\b(?:Conflict\s+of\s+Interest|Funding|Acknowledgments|References|Ethical\s+Approval|Data\s+Availability|Competing\s+Interests)\\b|\\n{3,})'
    contrib_match = re.search(author_contrib_regex, full_manuscript_text) 
    flag_claims_data_collection = False 
    collection_flag_details = "" 

    if contrib_match and contrib_match.group(1):
        author_contributions_section_text_specific = contrib_match.group(1).strip()
        collection_context_regex = r'\\b(?:we|authors?|I|study\s+group|team)\\s+(?:led\s+data\s+collection|collected|gathered|obtained|acquired|assembled|recruited|responsible\s+for\s+data\s+collection|managed\s+data|conducted\s+the\s+study|performed\s+the\s+experiments)\\s+(?:(?:the|these|our)\\s+)?(?:participants|subjects|(?:\\bNHANES\\b\\s+)?data|samples|specimens|information)\\b'
        if re.search(collection_context_regex, author_contributions_section_text_specific, re.IGNORECASE):
            flag_claims_data_collection = True
            collection_flag_details = "Claims data collection in 'Author Contributions': Yes (Potential issue for NHANES secondary analysis)."
        else:
            flag_claims_data_collection = False
            collection_flag_details = "Claims data collection in 'Author Contributions': Section found, but no specific data collection claim detected within it."
    else:
        collection_flag_details = "Claims data collection in 'Author Contributions': 'Author Contributions' section not found."
    
    all_details = [
        email_report_details,
        affiliation_count_details,
        affiliation_relevance_details, 
        collection_flag_details
    ]
    
    flags_triggered_count = sum([
        1 if flag_non_institutional_emails else 0,
        1 if flag_too_many_affiliations else 0,
        1 if flag_mismatched_affiliations else 0,
        1 if flag_claims_data_collection else 0
    ])
    
    passed = True 
    summary_message = "Author information analysis complete."

    if flags_triggered_count >= 2: 
        passed = False
        summary_message = f"Potential red flags in author information ({flags_triggered_count} issues detected)."
    elif flags_triggered_count == 1:
        summary_message = f"One potential issue found in author information."
    
    final_details_string = summary_message + "\\n" + "\\n".join(all_details)
    
    return {
        'passed': passed,
        'details': final_details_string
    }


# --- File Processing Functions ---
async def read_text_file(file_proxy): 
    content = await window.NHANESBridge.fetchTextFromFile(file_proxy)
    return content

async def read_docx_file(file_proxy): 
    if not hasattr(js, 'mammoth') or js.mammoth is None:
         raise RuntimeError("Mammoth.js library (js.mammoth) is not loaded or undefined.")
    array_buffer_js_proxy = await window.NHANESBridge.fetchArrayBufferFromFile(file_proxy)
    options_py = {'arrayBuffer': array_buffer_js_proxy}
    options_js = to_js(options_py, dict_converter=js.Object.fromEntries) 
    result = await js.mammoth.extractRawText(options_js)
    return result.value

async def read_pdf_file(file_proxy, progress_callback_proxy=None):
    if not hasattr(js, 'pdfjsLib') or js.pdfjsLib is None:
        raise RuntimeError("PDF.js library (js.pdfjsLib) is not loaded or undefined.")
    array_buffer_js_proxy = await window.NHANESBridge.fetchArrayBufferFromFile(file_proxy)
    js.pdfjsLib.GlobalWorkerOptions.workerSrc = 'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.16.105/pdf.worker.min.js'
    pdf_options_py = {'data': array_buffer_js_proxy}
    pdf_options_js = to_js(pdf_options_py, dict_converter=js.Object.fromEntries)
    pdf_document_loading_task = js.pdfjsLib.getDocument(pdf_options_js) 
    pdf = await pdf_document_loading_task.promise 
    page_texts = []
    for i in range(1, pdf.numPages + 1):
        page = await pdf.getPage(i)
        text_content_obj = await page.getTextContent() 
        text_items_js_array = text_content_obj.items 
        page_text_parts = []
        for item_js in text_items_js_array: 
            page_text_parts.append(str(item_js.str)) 
        page_texts.append(' '.join(page_text_parts))
        if progress_callback_proxy: 
            progress_callback_proxy(i, pdf.numPages)
    return '\\n\\n'.join(page_texts)

# --- UI Functions ---
def display_results(results_data):
    results_el = document.getElementById('results')
    results_content = document.getElementById('resultsContent')
    if not results_el or not results_content: console.error("Results elements not found"); return
    results_el.classList.remove('hidden')
    results_content.innerHTML = ''
    
    # Simplified display for NHANES-only
    final_res = results_data.get('finalResult', 'Unknown')
    fail_step = results_data.get('failStep', 0)
    
    document.getElementById('results').getElementsByTagName('h2')[0].textContent = "NHANES Manuscript Check Results"

    overall_class = 'check-item '
    if final_res == 'Pass': overall_class += 'pass'
    elif final_res == 'Fail' or final_res == 'Error': overall_class += 'fail'
    else: overall_class += 'not-nhanes' # Covers "Not NHANES" initial exit
    
    result_text = f"Overall Result: {final_res}"
    if final_res == 'Fail' and fail_step > 0: result_text += f" (Failed at Step {fail_step})"
    if final_res == 'Error': result_text = 'Processing Error'

    overall_result_div = document.createElement('div')
    overall_result_div.className = overall_class
    overall_result_div.innerHTML = f'<div class="summary">{result_text}</div>'
    results_content.appendChild(overall_result_div)

    if results_data.get('details'):
        summary_details_div = document.createElement('div'); summary_details_div.className = 'summary-details'; summary_details_div.innerHTML = '<h3>Processing Details:</h3>'
        ul = document.createElement('ul');
        for detail in results_data['details']:
            li = document.createElement('li'); li.textContent = detail
            if detail.startswith('✗'): li.style.color = '#dc3545'; li.style.fontWeight = 'bold'
            elif detail.startswith('✓'): li.style.color = '#28a745'
            elif detail.startswith('⚠️'): li.style.color = '#ffc107'; li.style.fontWeight = 'bold'
            ul.appendChild(li)
        summary_details_div.appendChild(ul); results_content.appendChild(summary_details_div)

    if results_data.get('checkResults'):
        checks_section = document.createElement('details'); checks_section.className = 'individual-checks'
        summary_toggle = document.createElement('summary'); summary_toggle.innerHTML = '<h3>Individual Check Details ▼</h3>'; checks_section.appendChild(summary_toggle)
        for check in results_data['checkResults']:
            item = document.createElement('div')
            is_skipped = check.get('skipped', False)
            is_passed = check.get('passed', False)
            status_cls = 'skipped' if is_skipped else ('pass' if is_passed else 'fail')
            status_icon = '⚪' if status_cls == 'skipped' else ('✓' if status_cls == 'pass' else '✗')
            status_color = '#6c757d' if status_cls == 'skipped' else ('#28a745' if status_cls == 'pass' else '#dc3545')
            item.className = f'check-item {status_cls}'
            details_html = check.get('details', '').replace('\\n', '<br>') 
            item.innerHTML = f"<h4>{check.get('checkName', 'Unknown')}: <span style='color:{status_color}; font-weight:bold;'>{status_icon} {status_cls[0].upper() + status_cls[1:]}</span></h4><p>{details_html}</p>"
            checks_section.appendChild(item)
        results_content.appendChild(checks_section)

# --- REVERTED Main orchestration function ---
def check_nhanes_manuscript(text, title='Untitled Manuscript'):
    js.console.log(f'[Python] Checking NHANES manuscript: {title}')
    
    # Initial check if it's an NHANES paper
    if not check_for_nhanes(text):
        return {
            'isNHANES': False, # Explicitly state it's not NHANES
            'finalResult': "Not NHANES",
            'details': ["The manuscript does not appear to use NHANES data."],
            'checkResults': []
        }
    
    results = {
        'isNHANES': True,
        'checkResults': [],
        'details': ["✓ STEP 1: Manuscript mentions NHANES."],
        'finalResult': "",
        'failStep': 0
    }

    # Truncate text at the first mention of "reference" (case-insensitive)
    # Using \\b for word boundary - needs quadruple \\\\ in JS string template
    ref_match = re.search(r'\\breference\\b', text, re.IGNORECASE) 
    text_for_checks = text 
    if ref_match:
        text_for_checks = text[:ref_match.start()]
        js.console.log(f"[Python] Found 'reference'. Truncating text for checks. Original length: {len(text)}, Truncated length: {len(text_for_checks)}")
    else:
        js.console.log("[Python] Word 'reference' not found. Using full text for checks.")
    
    # Lambda function needed for check_author_red_flags as it requires both full and truncated text
    author_red_flags_func = lambda truncated_text_arg: check_author_red_flags(text, truncated_text_arg) 

    # Define the sequence of checks to run (NHANES specific, excluding removed ones)
    checks_definitions = [
        {"name": "NHANES: Date Range Analysis", "func": check_nhanes_date_context_and_validation, "step": 2, "critical": False}, 
        {"name": "Generic: Title Template Check", "func": check_title_template, "step": 3, "critical": False}, 
        {"name": "Generic: Author Red Flags", "func": author_red_flags_func, "step": 4, "critical": False} 
    ]
    
    current_step_num = 1 # Start after initial NHANES mention check
    overall_passed = True # Assume pass unless a critical check fails (currently none are marked critical)

    for check_def in checks_definitions:
        # No need to log step transitions if steps are simple sequence now
        # if check_def["step"] > current_step_num:
        #    if results['finalResult'] != "Fail": results['details'].append(f"✓ STEP {current_step_num}: Checks passed.")
        #    current_step_num = check_def["step"]

        check_res = check_def["func"](text_for_checks) # Pass truncated text
        results['checkResults'].append({'checkName': check_def["name"], **check_res}) 
        
        # Simplified pass/fail - currently no critical checks defined in the list above
        # If you make a check critical again, this logic will apply
        if not check_res.get('passed') and not check_res.get('skipped'):
            if check_def.get("critical", False): 
                overall_passed = False
                results['failStep'] = check_def["step"]
                # Append failure detail only once per step
                fail_msg = f"✗ STEP {check_def['step']}: Failed critical check \\"{check_def['name']}\\"."
                if fail_msg not in results['details']:
                     results['details'].append(fail_msg)
                # break # Decide if you want to stop on first critical failure
            else:
                 # Append non-critical issue only once per check name if desired
                 warn_msg = f"⚠️ STEP {check_def['step']}: Non-critical issue in \\"{check_def['name']}\\"."
                 if warn_msg not in results['details']:
                      results['details'].append(warn_msg)

    # Final result determination
    if results['finalResult'] == "": # Only set if not already set (e.g., by 'Not NHANES')
        if overall_passed:
            results['finalResult'] = "Pass"
            # Remove generic step pass messages if any existed, add final pass
            results['details'] = [d for d in results['details'] if not d.startswith("✓ STEP")]
            results['details'].append("✓ All essential checks passed or had non-critical issues.")
        else:
             results['finalResult'] = "Fail"
             # Remove generic step pass messages if any existed
             results['details'] = [d for d in results['details'] if not d.startswith("✓ STEP")]
             if results['failStep'] == 0: results['failStep'] = current_step_num # Assign last step if specific critical fail step wasn't set
             fail_summary = f"✗ Manuscript failed critical check(s) around Step {results['failStep']}."
             if fail_summary not in results['details']:
                 results['details'].append(fail_summary)
                 
    return results

# --- Event Handlers ---
async def handle_file_upload(event_proxy): 
    js.console.log("[Python] handle_file_upload triggered")
    file_input_el = event_proxy.target 
    file_list_js = file_input_el.files 
    if not file_list_js or file_list_js.length == 0:
        js.console.log("[Python] No file selected.")
        return
    
    file_js_proxy = file_list_js.item(0) 
    js.console.log(f"[Python] File selected: name='{file_js_proxy.name}', type='{file_js_proxy.type}', size={file_js_proxy.size}")

    document.getElementById('results').classList.add('hidden')
    document.getElementById('resultsContent').innerHTML = ''
    window.NHANESBridge.showUILoading(f"Loading file: {str(file_js_proxy.name)}...")
    
    try:
        filename_py = str(file_js_proxy.name) 
        ext = filename_py.split('.')[-1].lower() if '.' in filename_py else ""
        content = ""
        js.console.log(f"[Python] Processing file extension: {ext}")

        if ext == 'txt':
            js.console.log("[Python] Calling read_text_file")
            content = await read_text_file(file_js_proxy)
        elif ext == 'docx':
            js.console.log("[Python] Calling read_docx_file")
            content = await read_docx_file(file_js_proxy)
        elif ext == 'pdf':
            js.console.log("[Python] Calling read_pdf_file")
            def update_pdf_progress(current_page, total_pages):
                window.NHANESBridge.showUILoading(f"Loading PDF: {filename_py} ({current_page}/{total_pages} pages)...")
            progress_proxy_for_js = create_proxy(update_pdf_progress)
            content = await read_pdf_file(file_js_proxy, progress_proxy_for_js)
        else:
            error_msg = f"Unsupported file type: .{ext}. Please upload .txt, .docx, or .pdf."
            js.console.error(f"[Python] {error_msg}")
            document.getElementById('manuscriptText').value = error_msg
            js.alert(error_msg)
            window.NHANESBridge.hideUILoading(False)
            return
        
        js.console.log(f"[Python] File content retrieved. Length: {len(content) if content else 0}.")
        document.getElementById('manuscriptText').value = content
        js.console.log("[Python] Textarea value set.")
        window.NHANESBridge.hideUILoading(True)
        js.console.log("[Python] hideUILoading called after file processing.")
        
    except Exception as e:
        js.console.error(f"[Python] Exception type in handle_file_upload: {type(e)}")
        js.console.error(f"[Python] Exception object in handle_file_upload: {repr(e)}")
        
        py_tb = traceback.format_exc()
        js.console.error(f"[Python] Python Traceback in handle_file_upload:\\n{py_tb}")

        error_msg_str = str(e)
        
        if isinstance(e, JsException):
            js.console.error(f"[Python] JsException caught: name='{str(e.name)}', message='{str(e.message)}'")
            if hasattr(e, 'stack') and e.stack: 
                js.console.error(f"[Python] JsException stack: {str(e.stack)}")
            if e.message: 
                error_msg_str = f"{str(e.name)}: {str(e.message)}" if e.name else str(e.message)
        
        if "is_undefined" in error_msg_str or (isinstance(e, JsException) and e.message and "undefined" in str(e.message).lower()):
            error_msg = "Error processing file: An undefined error occurred from a JavaScript library. Check console for details."
        elif "Could not find file in options" in error_msg_str : 
             error_msg = "Error processing DOCX: Mammoth.js could not find file data. Check console."
        elif "'str' object is not callable" in error_msg_str:
             error_msg = "Internal error: A function was unexpectedly a string. Check console."
        else:
            error_msg = f"Error processing file. Check console for details." # Generic for user

        document.getElementById('manuscriptText').value = f"ERROR: {error_msg}"
        js.alert(error_msg)
        window.NHANESBridge.hideUILoading(False)
    finally:
        if file_input_el: 
            try:
                file_input_el.value = '' 
                js.console.log("[Python] File input cleared.")
            except Exception as clear_ex:
                js.console.error(f"[Python] Error clearing file input: {str(clear_ex)}")


def handle_check_button(event):
    ta = document.getElementById('manuscriptText'); text = ta.value
    if not text.strip() or text.startswith("Loading") or text.startswith("Error") or text.startswith("Unsupported"):
        js.alert('Please paste manuscript text or upload a valid file first.'); return
    document.getElementById('results').classList.add('hidden'); window.NHANESBridge.showUILoading("Running NHANES checks...")
    
    async def run_checks_async():
        try: 
            check_results_obj = check_nhanes_manuscript(text, "Manuscript") # Use NHANES specific function
            display_results(check_results_obj)
        except Exception as e:
            py_tb = traceback.format_exc() 
            js.console.error(f"[Python] Error in handle_check_button (run_checks_async): {str(e)}\\nTraceback:\\n{py_tb}")
            display_results({'finalResult': "Error", 'details': [f"An unexpected error occurred during analysis: {str(e)}"], 'checkResults': []})
        finally:
            window.NHANESBridge.hideUILoading(True)
            results_content_el = document.getElementById('resultsContent')
            if results_content_el:
                html_content_py_str = str(results_content_el.innerHTML)
                if html_content_py_str.strip(): 
                    scroll_options_dict = {'behavior': 'smooth', 'block': 'start'}
                    scroll_options_js = to_js(scroll_options_dict, dict_converter=js.Object.fromEntries)
                    document.getElementById('results').scrollIntoView(scroll_options_js)
    js.setTimeout(create_proxy(run_checks_async), 10) 

def handle_clear_button(event):
    document.getElementById('manuscriptText').value = ''; document.getElementById('manuscriptFile').value = ''
    document.getElementById('results').classList.add('hidden'); document.getElementById('resultsContent').innerHTML = ''
    document.getElementById('checkButton').disabled = True

# --- Initialization ---
def initialize():
    js.console.log("[Python] Initializing NHANES Manuscript Checker...")
    try:
        js.eval("globalThis.pyodideCheckInstance = (obj, constr) => obj instanceof constr;")
        #js.console.log("[Python DEBUG] globalThis.pyodideCheckInstance helper defined.") # Optional debug log
    except Exception as e_init_eval:
        js.console.error(f"[Python DEBUG] Error defining JS helper: {str(e_init_eval)}")

    document.getElementById('pyodideLoading').classList.add('hidden'); document.getElementById('appContent').classList.remove('hidden')
    
    cb = document.getElementById('checkButton'); fi = document.getElementById('manuscriptFile')
    clb = document.getElementById('clearButton'); ta = document.getElementById('manuscriptText')

    if cb: cb.addEventListener('click', create_proxy(handle_check_button))
    if fi: fi.addEventListener('change', create_proxy(handle_file_upload))
    if clb: clb.addEventListener('click', create_proxy(handle_clear_button))
    if ta:
        def enable_check_if_text_py_callback(event_proxy): 
            text_val = ta.value 
            current_text = text_val.strip()
            # Need to escape the backslash in the line continuation for JS template literal
            is_placeholder = current_text.startswith("Loading") or \\
                             current_text.startswith("Error") or \\
                             current_text.startswith("Unsupported")
            cb.disabled = not bool(current_text) or is_placeholder
        
        ta.addEventListener('input', create_proxy(enable_check_if_text_py_callback))
        enable_check_if_text_py_callback(None)
    
    if cb and ta and not ta.value.strip():
        cb.disabled = True

    js.console.log("[Python] NHANES Manuscript Checker initialized and ready.")

initialize()
`;
        await pyodide.runPythonAsync(pythonCode);
        console.log("Python implementation loaded successfully!");
      } catch (error) {
        console.error("Error initializing Pyodide or Python script:", error);
        let err_stack = "No stack available.";
        if (error.stack) { 
            err_stack = error.stack;
        } else if (window.pyodide && error.name === "PythonError") { 
             try {
                err_stack = window.pyodide.runPython('import traceback; traceback.format_exc()');
             } catch (tb_err) {
                err_stack = "Could not format Python traceback from JS: " + tb_err.message;
             }
        }
        document.getElementById('pyodideLoading').innerHTML = 
          '<div style="color: #dc3545; font-weight: bold;">Error loading Python environment: ' + 
          error.message + '</div><div>Traceback: <pre>' + err_stack + '</pre></div>' +
          '<div>Please refresh the page to try again.</div>';
      }
    }
    main();
  </script>
</body>
</html>